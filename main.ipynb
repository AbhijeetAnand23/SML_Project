{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1ebaddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79f91539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove the outliers using the LOF Score method\n",
    "def removeOutliers(X, y):\n",
    "    # normalizing the data for better accuracy\n",
    "    scaler = StandardScaler()\n",
    "    X_new = scaler.fit_transform(X)\n",
    "\n",
    "    # detecing the outliers using n-neighbors as 10\n",
    "    clf = LocalOutlierFactor(n_neighbors=10)\n",
    "    temp = clf.fit_predict(X_new)\n",
    "    outliers = np.where(temp == -1)[0]\n",
    "    \n",
    "    # removing all the detected outliers from X_train and y_train and returning them as Dataframes\n",
    "    X_clean = np.delete(X, outliers, axis=0)\n",
    "    X_clean_df = pd.DataFrame(X_clean, columns=X.columns)\n",
    "    y_clean = np.delete(y, outliers, axis=0)\n",
    "    y_clean_df = pd.DataFrame(y_clean, columns=y.columns)\n",
    "\n",
    "    return X_clean_df, y_clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88a3467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the K-Means Clustering of the data and add a column into the data\n",
    "def kMeansClustering(X, data):\n",
    "    # computing the clusters using 20 classes\n",
    "    kmeans = KMeans(n_clusters=20, random_state=0).fit(X)\n",
    "    data['cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20984698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the PCA of the given data\n",
    "def computePCA(X, num):\n",
    "    # normalizing the data for better accuracy\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X)\n",
    "\n",
    "    # reducing the dimensions of the data according to the given parameter\n",
    "    pca = PCA(n_components=num)\n",
    "    PCAx = pd.DataFrame(pca.fit_transform(X_train))\n",
    "    return PCAx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c1245fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the LDA of the given data\n",
    "def computeLDA(X_train, y_train, toBeComputed):\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    lda.fit(X_train, y_train)\n",
    "    xLDA = lda.transform(toBeComputed)\n",
    "\n",
    "    return xLDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9595394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion to apply the Random Forest Classification Algorithm to predict the data\n",
    "def applyRandomForestClassifier(X_train, y_train, X_test, num):\n",
    "    y_train = (y_train.to_numpy()).ravel()\n",
    "    \n",
    "    # training the model according to the given value of the hyperparameter\n",
    "    rfc = RandomForestClassifier(n_estimators=num)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    y_pred = rfc.predict(X_test)\n",
    "\n",
    "    # returning the trained model as well, it will be use for K-Fold Cross Validation\n",
    "    return rfc, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0a5f650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform the K-Fold Cross Validation on the trained model\n",
    "def kFoldCrossValidation(model, X, y, k):\n",
    "    kf = KFold(n_splits=k, shuffle=True)\n",
    "    scores = cross_val_score(model, X, y, cv=kf)\n",
    "    print(\"Accuracy: %0.2f\" % (scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0d344e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save the predicted values as a .csv file\n",
    "def saveToCSV(y, filename):\n",
    "    with open(filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['ID', 'category'])\n",
    "        for i, value in enumerate(y):\n",
    "            writer.writerow([i, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "decb1b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Pre-processing\n",
    "\n",
    "dataTrain = pd.read_csv(\"D:\\\\IIIT Delhi\\\\4th Semester\\\\Courses\\\\Statistical Machine Learning\\\\Project\\\\data\\\\train.csv\")  # reading train.csv\n",
    "dataTrain = dataTrain.dropna()  # deleting the rows with missing values \n",
    "dataTrain = dataTrain.drop(['ID'], axis=1)  # droping the ID column from the data\n",
    "X_train = dataTrain.drop(['category'], axis=1)  # dropping the output column to form X_train\n",
    "y_train = pd.DataFrame(dataTrain.iloc[:,-1].values)  # taking the output column to form y_train\n",
    "\n",
    "dataTest = pd.read_csv(\"D:\\\\IIIT Delhi\\\\4th Semester\\\\Courses\\\\Statistical Machine Learning\\\\Project\\\\data\\\\test.csv\")  # reading test.csv\n",
    "dataTest = dataTest.dropna()  # deleting the rows with missing values\n",
    "X_test = dataTest.drop(['ID'], axis=1)  # droping the ID column to form X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7432eae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            n0        n1        n2        n3        n4        n5        n6   \n",
      "0     0.000000  0.000000  1.272801  0.290501  0.581446  0.000000  0.000000  \\\n",
      "1     0.000000  0.000000  1.542096  0.000000  0.896557  0.049978  0.000000   \n",
      "2     0.000000  0.000000  1.098595  0.571866  0.500355  0.000000  0.000000   \n",
      "3     0.000000  0.101666  1.159194  0.599216  0.893206  0.000000  0.200139   \n",
      "4     0.000000  0.000000  1.178603  0.362568  0.577602  0.000000  0.000000   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1211  0.000000  0.364963  0.770978  0.570945  0.996824  0.066661  0.000000   \n",
      "1212  0.083656  0.111407  1.753287  0.000000  1.197256  0.117919  0.000000   \n",
      "1213  0.000000  0.000000  1.545725  0.000000  0.842485  0.000000  0.000000   \n",
      "1214  0.000000  0.000000  1.194037  0.969926  0.499340  0.055789  0.000000   \n",
      "1215  0.000000  0.000000  1.020402  1.107121  0.361440  0.000000  0.000000   \n",
      "\n",
      "      n7        n8   n9  ...     n4088     n4089     n4090     n4091   \n",
      "0      0  0.000000  0.0  ...  0.869640  0.302432  0.953719  0.022545  \\\n",
      "1      0  0.117847  0.0  ...  0.622686  0.588427  0.524415  0.305426   \n",
      "2      0  0.493137  0.0  ...  0.913239  0.064404  0.531270  0.000000   \n",
      "3      0  0.645675  0.0  ...  1.243676  0.432523  0.701881  0.000000   \n",
      "4      0  0.079862  0.0  ...  0.736831  0.345906  0.878515  0.119000   \n",
      "...   ..       ...  ...  ...       ...       ...       ...       ...   \n",
      "1211   0  0.727390  0.0  ...  0.844568  0.084291  0.399840  0.225693   \n",
      "1212   0  0.000000  0.0  ...  0.659943  0.000000  0.457870  0.405808   \n",
      "1213   0  0.087607  0.0  ...  0.883849  0.589065  0.644103  0.194427   \n",
      "1214   0  0.221447  0.0  ...  0.645109  0.113367  0.877268  0.000000   \n",
      "1215   0  0.026102  0.0  ...  0.879483  0.406130  0.734420  0.000000   \n",
      "\n",
      "         n4092     n4093     n4094     n4095         category  cluster  \n",
      "0     0.498048  0.000000  0.034988  0.692382      Orange_Ripe        1  \n",
      "1     0.386204  0.000000  0.000000  0.668196      Banana_Ripe       11  \n",
      "2     0.471604  0.000000  0.000000  0.658250        Mango_Raw        9  \n",
      "3     0.589985  0.000000  0.000000  0.591165       Leeche_Raw       15  \n",
      "4     0.261441  0.000000  0.000000  0.458905       Mango_Ripe        1  \n",
      "...        ...       ...       ...       ...              ...      ...  \n",
      "1211  0.214918  0.000000  0.000000  0.356400  Strawberry_Ripe        2  \n",
      "1212  0.000000  0.342428  0.000000  0.019390      Banana_Ripe       10  \n",
      "1213  0.426330  0.000000  0.000000  0.764020      Banana_Ripe       11  \n",
      "1214  0.175457  0.000000  0.000000  0.367878       Guava_Ripe        6  \n",
      "1215  0.075351  0.000000  0.000000  0.316971       Guava_Ripe        6  \n",
      "\n",
      "[1216 rows x 4098 columns]\n"
     ]
    }
   ],
   "source": [
    "# forming the clusters of the training data and adding a new feauture in the dataset\n",
    "kMeansClustering(X_train, dataTrain)\n",
    "print(dataTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88406871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the data by removing the outliers\n",
    "X_clean, y_clean = removeOutliers(X_train, y_train)  # number of outliers computed = 86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5e71182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the X_train and X_test data for computation of PCA\n",
    "t = [X_clean, X_test]\n",
    "data = pd.concat(t)\n",
    "\n",
    "# reducing the data into 600 columns\n",
    "xPCA = computePCA(data, 600)\n",
    "\n",
    "# dividing the X_train and X_test which were merged earlier \n",
    "X_train = xPCA.iloc[:1130, :]  # total rows = 1216, outliers = 86, 1216 - 86 = 1130\n",
    "X_test = xPCA.iloc[1130:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25a6b524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing the LDA\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train, y_clean)\n",
    "\n",
    "# applying the same LDA model to both X_train and X_test\n",
    "xLDA = lda.transform(X_train)  # consist n-1 cloumns where n = classes i.e. 20, thus it has 19 columns\n",
    "x_testLDA = lda.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18635c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying the Random Forest Classification Technique to find the predicted value \n",
    "model, y_pred = applyRandomForestClassifier(xLDA, y_clean, x_testLDA, 100)  # taking value of the hyperparameter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8789cf26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "# using K-Fold Cross Validation to check our model and printing the accuracy\n",
    "kFoldCrossValidation(model, xLDA, y_clean, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a51c5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the predicted values in .csv file\n",
    "saveToCSV(y_pred, \"D:\\\\IIIT Delhi\\\\4th Semester\\Courses\\\\Statistical Machine Learning\\\\Project\\\\y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b253477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
